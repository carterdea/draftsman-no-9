# Database Plan

Technology, schema, migration strategy, and implementation phases for Draftsman No. 9 persistence.

## Technology Decisions

- **Database:** Postgres 16 (already specified in `docker-compose.yml` and `README.md`).
- **Driver:** `Bun.sql` (`import { sql } from "bun"`). Zero external dependencies.
- **Migrations:** Numbered `.sql` files in `packages/db/migrations/`, applied by a thin Bun-native runner.
- **ORM:** None. Hand-written SQL via tagged templates. Hand-written TypeScript types for row shapes.
- **Connection config:** Reads `POSTGRES_URL` (or `DATABASE_URL`) from environment automatically via `Bun.sql` defaults.

### Why Bun.sql

- Ships with the runtime — no `npm install` needed.
- Tagged template literals with automatic parameterization (injection-safe by default).
- Built-in connection pooling (`max`, `idleTimeout`, `maxLifetime`).
- Transactions with auto-commit/rollback (`sql.begin()`).
- Savepoints for partial rollback within state machine transitions.
- `SELECT ... FOR UPDATE` works normally for row-level locking.
- JSONB round-trips natively (JS object in, JS object out).
- Reads Postgres env vars out of the box (`POSTGRES_URL`, `DATABASE_URL`, `PGHOST`, etc.).

### What Bun.sql does not provide

- **Migration runner.** We write a small one (~40 lines) that reads `packages/db/migrations/*.sql` and tracks applied migrations in a `_migrations` table.
- **Schema-as-code type generation.** We define TypeScript types by hand in `packages/db/src/types.ts`. The schema is stable enough that this is fine.
- **`LISTEN`/`NOTIFY`.** Not yet supported in Bun.sql. Not needed — we use BullMQ/Redis for pub-sub and job signaling.

## Schema

### Naming conventions

- Table names: `snake_case`, plural (`jobs`, `job_events`).
- Column names: `snake_case`.
- Primary keys: `id` (UUID, generated by application via `crypto.randomUUID()`).
- Foreign keys: `<singular_table>_id` (e.g. `job_id`).
- Timestamps: `_at` suffix, `timestamptz`, default `now()`.
- Enums: Postgres `CREATE TYPE` for closed sets that benefit from DB-level enforcement.
- JSONB: Used for semi-structured payloads where the shape varies per event kind or is opaque to the control plane.

### Enum types

```sql
CREATE TYPE job_status AS ENUM (
  'queued',
  'running',
  'waiting_for_input',
  'resumed',
  'completed',
  'failed',
  'canceled',
  'expired'
);

CREATE TYPE invocation_mode AS ENUM (
  'investigate',
  'fix'
);

CREATE TYPE invocation_source AS ENUM (
  'trello',
  'slack',
  'mcp',
  'internal'
);

CREATE TYPE source_type AS ENUM (
  'trello_ticket',
  'plain_text_intake'
);

CREATE TYPE question_status AS ENUM (
  'open',
  'answered',
  'expired'
);
```

### Table: `jobs`

Central resource. Every invocation creates exactly one job. All other tables reference back to this.

```sql
CREATE TABLE jobs (
  id                    uuid PRIMARY KEY,
  idempotency_key       text UNIQUE NOT NULL,

  -- lifecycle
  status                job_status NOT NULL DEFAULT 'queued',

  -- invocation
  mode                  invocation_mode NOT NULL,
  source                invocation_source NOT NULL,
  source_type           source_type NOT NULL DEFAULT 'trello_ticket',
  external_event_id     text NOT NULL,

  -- invoker
  invoker_id            text NOT NULL,
  invoker_display_name  text,

  -- repo (nullable until resolved)
  repo_owner            text,
  repo_name             text,
  repo_resolved_at      timestamptz,

  -- ticket snapshot
  ticket_url            text,
  ticket_title          text,
  ticket_text           text,

  -- outcome
  pr_url                text,

  -- configuration
  overrides             jsonb NOT NULL DEFAULT '{}',
  requested_skills      jsonb NOT NULL DEFAULT '[]',

  -- timestamps
  started_at            timestamptz,
  completed_at          timestamptz,
  canceled_at           timestamptz,
  expired_at            timestamptz,
  created_at            timestamptz NOT NULL DEFAULT now(),
  updated_at            timestamptz NOT NULL DEFAULT now()
);

-- Queries: list by status, list by repo, lookup by idempotency key
CREATE INDEX idx_jobs_status ON jobs (status);
CREATE INDEX idx_jobs_repo ON jobs (repo_owner, repo_name);
CREATE INDEX idx_jobs_source ON jobs (source, external_event_id);
CREATE INDEX idx_jobs_created_at ON jobs (created_at);
```

### Table: `job_events`

Append-only audit trail. Immutable after insert. This is the core audit primitive — every meaningful action gets a row here.

```sql
CREATE TABLE job_events (
  id          bigint GENERATED ALWAYS AS IDENTITY PRIMARY KEY,
  job_id      uuid NOT NULL REFERENCES jobs(id),
  kind        text NOT NULL,
  payload     jsonb NOT NULL DEFAULT '{}',
  created_at  timestamptz NOT NULL DEFAULT now()
);

-- Cursor-paginated audit stream per job
CREATE INDEX idx_job_events_job_created ON job_events (job_id, created_at);
-- Filter by kind across all jobs (ops queries)
CREATE INDEX idx_job_events_kind ON job_events (kind, created_at);
```

Event `kind` values (not a Postgres enum — new kinds get added without migrations):

| Kind | When | Payload contains |
|------|------|------------------|
| `job_created` | Job row inserted | invocation envelope snapshot |
| `job_started` | Worker begins execution | runner backend, agent version |
| `repo_resolved` | Repo identified | owner, name, confidence, method |
| `iteration_started` | Ralph loop iteration N begins | iteration number |
| `command_executed` | Validation/agent command ran | command, exit code, duration, truncated output |
| `validation_ran` | Test/lint/typecheck/build result | command, pass/fail, summary |
| `needs_input` | Runner requests human input | question_id, checkpoint_id |
| `answer_received` | Human answered | question_id, answer_id, source, responder |
| `job_resumed` | Execution restarted from checkpoint | checkpoint_id, answer_id |
| `pr_created` | PR opened | pr_url, files_changed, loc_delta |
| `delivery_posted` | Trello/Slack comment posted | target, comment_id |
| `attachment_uploaded` | Artifact attached to Trello/Slack | artifact_id, target |
| `attachment_warning` | Attachment upload failed (non-blocking) | artifact_id, error |
| `job_completed` | Terminal success | summary |
| `job_failed` | Terminal failure | error, summary |
| `job_canceled` | Canceled by user or auto-cancel | reason, requested_by, source |
| `job_expired` | 24h question timeout | question_id |
| `queue_job_dead` | BullMQ dead-letter | attempts, last_error |

### Table: `job_checkpoints`

Saved execution state for pause/resume. Opaque to the control plane — the runner writes it, the runner reads it back.

```sql
CREATE TABLE job_checkpoints (
  id               uuid PRIMARY KEY,
  job_id           uuid NOT NULL REFERENCES jobs(id),
  checkpoint_data  jsonb NOT NULL,
  created_at       timestamptz NOT NULL DEFAULT now()
);

CREATE INDEX idx_job_checkpoints_job ON job_checkpoints (job_id);
```

### Table: `job_questions`

Structured questions posted to humans when the runner hits ambiguity or risk.

```sql
CREATE TABLE job_questions (
  id                uuid PRIMARY KEY,
  job_id            uuid NOT NULL REFERENCES jobs(id),
  checkpoint_id     uuid NOT NULL REFERENCES job_checkpoints(id),
  status            question_status NOT NULL DEFAULT 'open',
  question_text     text NOT NULL,
  question_choices  jsonb,
  freeform_allowed  boolean NOT NULL DEFAULT false,
  context_snippet   text,
  delivery_targets  jsonb NOT NULL DEFAULT '{}',
  asked_at          timestamptz NOT NULL DEFAULT now(),
  expires_at        timestamptz NOT NULL
);

CREATE INDEX idx_job_questions_job ON job_questions (job_id);
CREATE INDEX idx_job_questions_status ON job_questions (status) WHERE status = 'open';
```

### Table: `job_answers`

Human responses. Linked to a question. Can come from any channel.

```sql
CREATE TABLE job_answers (
  id                    uuid PRIMARY KEY,
  question_id           uuid NOT NULL REFERENCES job_questions(id),
  job_id                uuid NOT NULL REFERENCES jobs(id),
  source                invocation_source NOT NULL,
  source_event_id       text NOT NULL,
  responder_id          text NOT NULL,
  responder_display_name text,
  answer_payload        jsonb NOT NULL,
  created_at            timestamptz NOT NULL DEFAULT now(),

  UNIQUE (question_id, source_event_id)
);

CREATE INDEX idx_job_answers_question ON job_answers (question_id);
CREATE INDEX idx_job_answers_job ON job_answers (job_id);
```

### Table: `repo_mappings`

Trello label → repo resolution. Used by the repo resolver pipeline.

```sql
CREATE TABLE repo_mappings (
  id                uuid PRIMARY KEY,
  trello_label_id   text,
  trello_label_name text,
  repo_owner        text NOT NULL,
  repo_name         text NOT NULL,
  created_at        timestamptz NOT NULL DEFAULT now(),
  updated_at        timestamptz NOT NULL DEFAULT now(),

  UNIQUE (trello_label_id)
);

CREATE INDEX idx_repo_mappings_label_name ON repo_mappings (trello_label_name);
CREATE INDEX idx_repo_mappings_repo ON repo_mappings (repo_owner, repo_name);
```

### Table: `repo_profiles`

Per-repo behavior configuration: validation commands, guardrail limits, prompt profile.

```sql
CREATE TABLE repo_profiles (
  id                    uuid PRIMARY KEY,
  repo_owner            text NOT NULL,
  repo_name             text NOT NULL,
  profile_type          text NOT NULL DEFAULT 'unknown',
  validation_commands   jsonb NOT NULL DEFAULT '[]',  -- array of { name, command, required }
  path_allowlist        jsonb,
  risky_paths           jsonb,
  default_skills        jsonb NOT NULL DEFAULT '[]',
  max_iterations        int NOT NULL DEFAULT 5,
  max_runtime_seconds   int NOT NULL DEFAULT 900,
  max_files_changed     int NOT NULL DEFAULT 20,
  max_loc_delta         int NOT NULL DEFAULT 500,
  created_at            timestamptz NOT NULL DEFAULT now(),
  updated_at            timestamptz NOT NULL DEFAULT now(),

  UNIQUE (repo_owner, repo_name)
);
```

### Table: `trello_board_configs`

Delivery policy per Trello board: which list to move cards to, transition rules, comment templates.

```sql
CREATE TABLE trello_board_configs (
  id                        uuid PRIMARY KEY,
  board_id                  text UNIQUE NOT NULL,
  ready_for_review_list_id  text NOT NULL,
  transition_rules          jsonb NOT NULL DEFAULT '{}',
  comment_template          text,
  created_at                timestamptz NOT NULL DEFAULT now(),
  updated_at                timestamptz NOT NULL DEFAULT now()
);
```

### Table: `_migrations`

Internal bookkeeping for the migration runner. Not part of the application domain.

```sql
CREATE TABLE _migrations (
  id          int PRIMARY KEY,
  filename    text NOT NULL,
  applied_at  timestamptz NOT NULL DEFAULT now()
);
```

## Migration Strategy

### File structure

```
packages/db/
  migrations/
    001_initial_schema.sql
    002_add_repo_profiles.sql
    ...
  src/
    index.ts          -- connection factory, exports sql instance
    types.ts          -- TypeScript row types for all tables
    migrate.ts        -- migration runner
    migrate.test.ts   -- migration runner tests
    queries/
      jobs.ts         -- job CRUD + status transitions
      events.ts       -- audit event append + cursor query
      questions.ts    -- question/answer lifecycle
      repos.ts        -- repo mappings + profiles
      trello.ts       -- trello board config
```

### Migration runner behavior

1. Connect to Postgres via `Bun.sql`.
2. Create `_migrations` table if it doesn't exist.
3. Read `packages/db/migrations/*.sql`, sorted by numeric prefix.
4. Compare against `_migrations` rows.
5. Run unapplied migrations in order, each in its own transaction.
6. Insert a row into `_migrations` for each successful migration.
7. Fail loudly and stop on any error (no partial state).

Invoked via:
- `bun run migrate` (add to root `package.json` scripts)
- Called automatically in dev startup (optional, gated by env flag)
- Never auto-run in production — explicit operator action only

### Migration rules

- Migrations are append-only. Never edit an applied migration.
- Destructive changes (drop column, drop table) require a new migration with a clear comment explaining why.
- Each migration file is a single transaction (wrap in `BEGIN; ... COMMIT;`).
- Use `IF NOT EXISTS` / `IF EXISTS` guards for idempotency where appropriate.

## Connection Management

### Shared connection factory

`packages/db/src/index.ts` exports a configured `sql` instance:

```ts
import { SQL } from "bun";

const db = new SQL({
  url: process.env.POSTGRES_URL || process.env.DATABASE_URL,
  max: 10,
  idleTimeout: 30,
  maxLifetime: 3600,
});

export { db };
```

Both `apps/api` and `apps/worker` import from `@draftsman/db` and share the same connection config. Each process gets its own pool (they're separate OS processes).

### Pool sizing

- API: `max: 10` (handles concurrent HTTP requests)
- Worker: `max: 5` (BullMQ concurrency is 5 for `draftsman:jobs`)
- Configurable via env: `DB_POOL_MAX`

### Health check

Expose a `checkDbHealth()` function that runs `SELECT 1` and returns connected/disconnected status. Used by both API `/health` and worker healthcheck.

## TypeScript Types

Hand-written in `packages/db/src/types.ts`. These are row shapes, not ORM models.

```ts
// Enum types matching Postgres enums
export type JobStatus =
  | "queued"
  | "running"
  | "waiting_for_input"
  | "resumed"
  | "completed"
  | "failed"
  | "canceled"
  | "expired";

export type InvocationMode = "investigate" | "fix";

export type InvocationSource = "trello" | "slack" | "mcp" | "internal";

export type SourceType = "trello_ticket" | "plain_text_intake";

export type QuestionStatus = "open" | "answered" | "expired";

// Row types
export interface JobRow {
  id: string;
  idempotency_key: string;
  status: JobStatus;
  mode: InvocationMode;
  source: InvocationSource;
  source_type: SourceType;
  external_event_id: string;
  invoker_id: string;
  invoker_display_name: string | null;
  repo_owner: string | null;
  repo_name: string | null;
  repo_resolved_at: Date | null;
  ticket_url: string | null;
  ticket_title: string | null;
  ticket_text: string | null;
  pr_url: string | null;
  overrides: Record<string, unknown>;
  requested_skills: string[];
  started_at: Date | null;
  completed_at: Date | null;
  canceled_at: Date | null;
  expired_at: Date | null;
  created_at: Date;
  updated_at: Date;
}

export interface JobEventRow {
  id: number;
  job_id: string;
  kind: string;
  payload: Record<string, unknown>;
  created_at: Date;
}

export interface JobCheckpointRow {
  id: string;
  job_id: string;
  checkpoint_data: Record<string, unknown>;
  created_at: Date;
}

export interface JobQuestionRow {
  id: string;
  job_id: string;
  checkpoint_id: string;
  status: QuestionStatus;
  question_text: string;
  question_choices: unknown[] | null;
  freeform_allowed: boolean;
  context_snippet: string | null;
  delivery_targets: Record<string, unknown>;
  asked_at: Date;
  expires_at: Date;
}

export interface JobAnswerRow {
  id: string;
  question_id: string;
  job_id: string;
  source: InvocationSource;
  source_event_id: string;
  responder_id: string;
  responder_display_name: string | null;
  answer_payload: Record<string, unknown>;
  created_at: Date;
}

export interface RepoMappingRow {
  id: string;
  trello_label_id: string | null;
  trello_label_name: string | null;
  repo_owner: string;
  repo_name: string;
  created_at: Date;
  updated_at: Date;
}

export interface ValidationCommand {
  name: string;
  command: string;
  required: boolean;
}

export interface RepoProfileRow {
  id: string;
  repo_owner: string;
  repo_name: string;
  profile_type: string;
  validation_commands: ValidationCommand[];
  path_allowlist: string[] | null;
  risky_paths: string[] | null;
  default_skills: string[];
  max_iterations: number;
  max_runtime_seconds: number;
  max_files_changed: number;
  max_loc_delta: number;
  created_at: Date;
  updated_at: Date;
}

export interface TrelloBoardConfigRow {
  id: string;
  board_id: string;
  ready_for_review_list_id: string;
  transition_rules: Record<string, unknown>;
  comment_template: string | null;
  created_at: Date;
  updated_at: Date;
}
```

## Query Patterns

### Job creation (idempotent)

```ts
const [job] = await db`
  INSERT INTO jobs (id, idempotency_key, mode, source, source_type, external_event_id,
                    invoker_id, invoker_display_name, ticket_url, ticket_title, ticket_text,
                    overrides, requested_skills)
  VALUES (${id}, ${key}, ${mode}, ${source}, ${sourceType}, ${eventId},
          ${invokerId}, ${invokerName}, ${ticketUrl}, ${ticketTitle}, ${ticketText},
          ${JSON.stringify(overrides)}, ${JSON.stringify(skills)})
  ON CONFLICT (idempotency_key) DO NOTHING
  RETURNING *
`;
const deduped = job === undefined;
```

### Status transition (guarded, atomic)

```ts
await db.begin(async (tx) => {
  const [job] = await tx`
    SELECT status FROM jobs WHERE id = ${jobId} FOR UPDATE
  `;
  if (!isValidTransition(job.status, nextStatus)) {
    throw new Error(`invalid transition: ${job.status} -> ${nextStatus}`);
  }
  await tx`
    UPDATE jobs SET status = ${nextStatus}, updated_at = now() WHERE id = ${jobId}
  `;
  await tx`
    INSERT INTO job_events (job_id, kind, payload)
    VALUES (${jobId}, ${eventKind}, ${JSON.stringify(eventPayload)})
  `;
});
```

### Audit stream (cursor-paginated)

```ts
const events = await db`
  SELECT * FROM job_events
  WHERE job_id = ${jobId}
    AND created_at > ${cursor}
  ORDER BY created_at ASC
  LIMIT ${limit}
`;
```

### Question expiry check

```ts
const [question] = await db`
  SELECT * FROM job_questions
  WHERE id = ${questionId}
    AND status = 'open'
    AND expires_at > now()
`;
if (!question) throw new Error("question expired or already answered");
```

## State Machine Transitions

Valid transitions enforced in application code (and auditable via `job_events`):

```
queued             -> running, canceled
running            -> waiting_for_input, completed, failed, canceled
waiting_for_input  -> resumed, expired, canceled
resumed            -> running
```

Rules:
- `running -> running` is not valid. The intermediate `resumed` state exists so every transition is auditable.
- Terminal states (`completed`, `failed`, `canceled`, `expired`) allow no further transitions.
- Every transition inserts a `job_events` row in the same transaction.

## Implementation Phases

### Phase 1: Foundation

- [ ] Write migration runner (`packages/db/src/migrate.ts`).
- [ ] Write `001_initial_schema.sql` (all tables, enums, indexes from this plan).
- [ ] Write connection factory (`packages/db/src/index.ts`) replacing current stub.
- [ ] Write TypeScript types (`packages/db/src/types.ts`).
- [ ] Write `checkDbHealth()` returning connection status.
- [ ] Add `bun run migrate` script to root `package.json`.
- [ ] Add migration runner tests (applies cleanly, skips already-applied, fails on bad SQL).
- [ ] Run `bun run typecheck` and `bun run test` to confirm nothing breaks.

### Phase 2: Query Layer

- [ ] Write `packages/db/src/queries/jobs.ts` — create (idempotent), get, list (filtered), update status (guarded).
- [ ] Write `packages/db/src/queries/events.ts` — append event, cursor-paginated list by job.
- [ ] Write `packages/db/src/queries/questions.ts` — create question, answer question (with expiry check), expire question.
- [ ] Write `packages/db/src/queries/repos.ts` — CRUD for repo mappings and profiles.
- [ ] Write `packages/db/src/queries/trello.ts` — CRUD for trello board config.
- [ ] Add unit tests for each query module (against a real test database).
- [ ] Run `bun run check`.

### Phase 3: Integration

- [ ] Wire `apps/api` to use `@draftsman/db` for job creation, status queries, audit stream, cancel, resume.
- [ ] Wire `apps/worker` to use `@draftsman/db` for job state loading, checkpoint persistence, status transitions.
- [ ] Update `docker-compose.yml` to add Postgres port mapping for local dev access.
- [ ] Add `bun run migrate` to dev startup sequence.
- [ ] Integration tests: API → DB → worker round-trip.

## Testing Strategy

- **Migration tests:** Apply all migrations to a fresh database, verify tables exist with correct columns.
- **Query tests:** Run against a real Postgres instance (Docker). Each test uses a transaction that rolls back, so tests are isolated and fast.
- **State machine tests:** Verify valid transitions succeed and invalid transitions throw.
- **Idempotency tests:** Duplicate insert returns existing row, not error.
- **Cursor pagination tests:** Verify ordering and boundary behavior.

Test database: Use the same `docker-compose.yml` Postgres instance. Tests connect to a dedicated `draftsman_test` database. Add a `bun run test:db` script that ensures the test database exists before running.

## Resolved Questions

- **`job_events.payload` size limit:** Yes — cap at 10KB at the application layer. Truncate with `"truncated": true` in the payload. Full output can go to log files or artifact storage if needed later. Primary risk is `command_executed` events with large test/lint stdout.
- **`repo_profiles.validation_commands` shape:** Array of objects: `{ "name": string, "command": string, "required": boolean }`. Each repo gets its own commands (Shopify theme repos use `shopify theme check`, Rails repos use `bundle exec rspec`, Bun repos use `bun test`, etc.). The `required` field controls whether failure is a hard gate (blocks PR) or a warning (noted in audit trail).
- **`job_cancellations` table:** Removed. The `job_canceled` event in `job_events` captures `reason`, `requested_by`, and `source` in its JSONB payload. The `canceled_at` timestamp lives on the `jobs` row. No separate table needed.

## Done Looks Like

- `bun run migrate` applies schema to a fresh Postgres and is idempotent on re-run.
- All tables from this plan exist with correct types, constraints, and indexes.
- Query modules cover create, read, update for all tables with proper transaction boundaries.
- State machine transitions are guarded and every transition is audited.
- Tests pass against a real Postgres instance.
- `apps/api` and `apps/worker` can import `@draftsman/db` and interact with all tables.
- Zero external npm dependencies in `packages/db`.
